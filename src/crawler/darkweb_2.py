import aiohttp
import asyncio
from aiohttp_socks import ProxyConnector  # âœ… SOCKS5 í”„ë¡ì‹œ ì§ì ‘ ì„¤ì •
from bs4 import BeautifulSoup
from datetime import datetime, timezone

# 1ï¸âƒ£ í¬ë¡¤ë§í•  ë‹¤í¬ì›¹ URL
url = "http://7ukmkdtyxdkdivtjad57klqnd3kdsmq6tp45rrsxqnu76zzv3jvitlqd.onion/"

# 2ï¸âƒ£ HTTP ìš”ì²­ í—¤ë” ì„¤ì •
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
}

# 3ï¸âƒ£ SOCKS5 í”„ë¡ì‹œ ì„¤ì • (Tor ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©)
proxy_host = "127.0.0.1"
proxy_port = 9050

async def crawl_darkweb2():
    """ ë‹¤í¬ì›¹ í¬ë¡¤ë§ í•¨ìˆ˜ - ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ """
    try:
        # ğŸ”¹ SOCKS5 í”„ë¡ì‹œ ì»¤ë„¥í„° ìˆ˜ë™ ì„¤ì •
        connector = ProxyConnector.from_url(f"socks5://{proxy_host}:{proxy_port}")

        async with aiohttp.ClientSession(connector=connector) as session:
            async with session.get(url, headers=headers, timeout=30) as response:
                response.raise_for_status()  # HTTP ì˜¤ë¥˜ ì²´í¬
                html = await response.text()  # ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ HTML ê°€ì ¸ì˜¤ê¸°
                print("âœ… í˜ì´ì§€ ìš”ì²­ ì„±ê³µ!")

    except aiohttp.ClientError as e:
        print(f"âŒ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        return []  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    # ğŸ”¹ HTML íŒŒì‹±
    soup = BeautifulSoup(html, "html.parser")
    leak_data_2 = []

    # ğŸ”¹ ê° ì¹´ë“œ ë°ì´í„° í¬ë¡¤ë§
    for card in soup.find_all("div", class_="border border-warning card-body shadow-lg"):
        title = card.find("h4", class_="border-danger card-title text-start text-white")
        title_text = title.get_text(strip=True) if title else "ì œëª© ì—†ìŒ"

        website_tag = card.find("h6", class_="card-subtitle mb-2 text-muted text-start")
        website_link = website_tag.find("a")["href"] if website_tag and website_tag.find("a") else "ë§í¬ ì—†ìŒ"

        description = card.find("p", class_="card-text text-start text-white")
        description_text = description.get_text(strip=True) if description else "ì„¤ëª… ì—†ìŒ"

        insert_time = datetime.now(timezone.utc).isoformat()

        # ğŸ”¹ ë°ì´í„° ì €ì¥ (ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€)
        leak_data_2.append({
            "title": title_text,
            "website": website_link,
            "description": description_text,
            "insert_time": insert_time
        })

    print(f"ğŸ” {len(leak_data_2)}ê°œì˜ ë°ì´í„°ê°€ í¬ë¡¤ë§ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return leak_data_2  # âœ… ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜
